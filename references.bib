@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{mirage2023,
  title={Are Emergent Abilities of Large Language Models a Mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}

@article{catastrophic2024,
  title={On Catastrophic Inheritance of Large Foundation Models},
  author={Jiang, Yuxin and Jiang, Yujia and Jiang, Yufan and Jiang, Yujie and Jiang, Yuqi and Jiang, Yujin},
  journal={arXiv preprint arXiv:2401.12789},
  year={2024}
}

@article{rectified2024,
  title={Selecting Large Language Models to Fine-tune via Rectified Scaling Law},
  author={Zhang, Zheng and Zhao, Tianyi and Jiang, Yujia and Zhao, Tong and Zhao, Tianyi},
  journal={arXiv preprint arXiv:2402.18540},
  year={2024}
} 